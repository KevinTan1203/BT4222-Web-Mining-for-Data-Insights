{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is used for the generation of keywords variations which can be used to sieve out sentences that mirrors our ESG sub-pillar features\n",
    "\n",
    "For instance see the image below for some illustration on ESG sub-pillar constituents\n",
    "\n",
    "![esgmsci](https://www.visualcapitalist.com/wp-content/uploads/2021/03/shareable-5.jpg)\n",
    "\n",
    "For each sub-pillar, we will pick out the keywords and use NLP derive the vector for each word so as to find it's nearest neighbours. This gives us a series of words that are similar/closely related to the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List is not exhaustive. Feel free to populate more words related to each sub-pillar\n",
    "\n",
    "environment_features = ['climate', 'pollution', 'energy', 'waste', 'electric', 'emission', 'green', 'technology', 'toxic']\n",
    "\n",
    "social_features = ['human', 'labor', 'privacy', 'data security', 'safety', 'welfare', 'management', 'equality', 'equal', 'equity', 'pay', 'salary', 'allowance']\n",
    "\n",
    "governance_features = ['governance', 'corrupt', 'equity', 'equal', 'equality', 'accounting', 'ethics', 'transparency', 'tax', 'ownership', 'shareholder', 'control', 'pay']\n",
    "\n",
    "esg_keywords = [\n",
    "                'best-in-class', 'carbon footprint', 'carbon pricing', 'clean technology', 'engagement', 'environmental factors', 'esg integration', 'ethical investing', 'exclusions', \n",
    "                'negative screening', 'governance factors', 'green bond', 'greenwashing', 'human rights', 'impact investments', 'modern slavery', 'PRI', 'proxy voting', \n",
    "                'renewable energy', 'screening', 'social factors', 'SRI', 'stewardship', 'thematic investing', 'SDG', 'values-based investing', 'voting rights', 'biodiversity', \n",
    "                'carbon capture and storage', 'circular economy', 'climate action tracker', 'climate clocks', 'climate funds', \n",
    "                'climate transition benchmarks', 'greenhouse gas emissions', 'net zero carbon pledge and initiative', 'paris agreement', 'paris-aligned benchmarks', \n",
    "                'PFAS', 'scope 1', 'scope 2', 'scope 3', 'sdg funds', 'sin stocks', 'smart esg scores', 'social sustainability', 'stewardship code', 'stranded assets', \n",
    "                'sustainable investing', 'sustainability reporting', 'sustainable supply chains', 'sustainable technology', 'thermal coal exposure', 'triple bottom line', 'un global impact','green','low-carbon'\n",
    "                ]\n",
    "  \n",
    "lst = [\n",
    "        'acidification','biofuel','carbon','carbon dioxide','climate','co2','climate change','decarbonisation','decarbonization','energy transmission','energy','energy transition',\n",
    "        'energy storage','emissions','emission control','fossil fuels','geothermal energy','geothermal','greenhouse gas','greenhouse','hydrocarbons','LNG','liquefied natural gas',\n",
    "        'ozone','renewable resources','sng','synthetic natural gas','thermal energy','thermal','wind power','wind'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "from scipy import spatial\n",
    "import gensim\n",
    "from numba import jit\n",
    "import nltk, time, spacy, numpy as np\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(max_features = 50 ,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_features=50, stop_words='english')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Udemy Version\n",
    "def cosine_similarity(vect1, vect2):\n",
    "    return 1 - spatial.distance.cosine(vect1, vect2)\n",
    "\n",
    "def similar_words(wordOfInterest, topwords):\n",
    "    computed_similarities = []\n",
    "\n",
    "    # Convert word of interest to as vector\n",
    "    woi_vector = nlp(wordOfInterest).vector\n",
    "    for word in nlp.vocab:\n",
    "        if word.has_vector and word.is_lower and word.is_alpha:\n",
    "            similarity = cosine_similarity(woi_vector, word.vector)\n",
    "            computed_similarities.append((word, similarity))\n",
    "    sortedWords = sorted(computed_similarities, key = lambda item: -item[1])\n",
    "    return [w[0].text for w in sortedWords[:topwords]]\n",
    "\n",
    "\n",
    "# Towards Data Science Version\n",
    "def most_similar(word, topn):\n",
    "    word = nlp.vocab[str(word)]\n",
    "    queries = [\n",
    "        w for w in word.vocab if w.is_lower == word.is_lower and w.prob >= -15 and np.count_nonzero(w.vector)\n",
    "    ]\n",
    "    by_similarity = sorted(queries, key=lambda w: word.similarity(w), reverse=True)\n",
    "    return [(w.lower_,w.similarity(word)) for w in by_similarity[:topn+1] if w.lower_ != word.lower_]\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def cosine_similarity_numba(u:np.ndarray, v:np.ndarray):\n",
    "    assert(u.shape[0] == v.shape[0])\n",
    "    uv = 0\n",
    "    uu = 0\n",
    "    vv = 0\n",
    "    for i in range(u.shape[0]):\n",
    "        uv += u[i]*v[i]\n",
    "        uu += u[i]*u[i]\n",
    "        vv += v[i]*v[i]\n",
    "    cos_theta = 1\n",
    "    if uu != 0 and vv != 0:\n",
    "        cos_theta = uv/np.sqrt(uu*vv)\n",
    "    return cos_theta\n",
    "\n",
    "\n",
    "# Stack Overflow\n",
    "def similar_words_to_given_word(word, top):\n",
    "    doc = nlp.vocab\n",
    "    similarities = {}  \n",
    "    tok = nlp(word)\n",
    "    similarities[tok.text] = {}\n",
    "    for tok_ in doc:\n",
    "        similarities[tok.text].update({tok_.text:tok.similarity(tok_)})\n",
    "    \n",
    "    topWords = lambda x: {k: v for k, v in sorted(similarities[x].items(), key=lambda item: item[1], reverse=True)[:top]}\n",
    "    return topWords(word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['climate', 'pollution', 'energy', 'that', 'what', 'there', 'how', 'we', 'why', 'could']\n",
      "{'pollution': 1.0, 'toxic': 0.6272381319120371, 'waste': 0.5875696368785799, 'climate': 0.5568534621970989, 'energy': 0.45739895449558304, 'cause': 0.4362784676469133, 'Cause': 0.4362784676469133, 'Mass': 0.32694304829807114, 'could': 0.2815637073990229, 'Could': 0.2815637073990229}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevintanyuejun/opt/anaconda3/envs/bt4222_env/lib/python3.7/site-packages/ipykernel_launcher.py:51: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n"
     ]
    }
   ],
   "source": [
    "print(similar_words(environment_features[0], 10))\n",
    "# print(most_similar(environment_features[0], 10))\n",
    "print(similar_words_to_given_word(environment_features[1], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this: https://github.com/kavgan/nlp-in-practice/blob/master/word2vec/Word2Vec.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, we will be generating all the ESG keywords for the individual pillar and store them into a text.file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "514f02c4191bf6635aa39c3f7e028852a268bfb4c225c025b4739bc9aac37ae9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('bt4222_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
