{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bNxHQqJzKlRS"
   },
   "source": [
    "# Getting Data from TWITTER \n",
    "\n",
    "- https://www.twitter.com/leehsienloong\n",
    "- https://www.twitter.com/STcom\n",
    "- https://www.twitter.com/stompsingapore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXgED82hKlRT"
   },
   "source": [
    "# Getting Twitter API keys\n",
    "\n",
    "In order to access Twitter Streaming API, we need to get 4 pieces of information from Twitter: API key, API secret, Access token and Access token secret. Follow the steps below to get all 4 elements:\n",
    "\n",
    "- Create a Twitter account if you do not already have one.\n",
    "- Go to https://apps.twitter.com/ and log in with your Twitter credentials.\n",
    "- Click **Create New App**\n",
    "- Fill out the form, agree to the terms, and click **Create your Twitter application**\n",
    "- In the next page, click on **API keys** tab, and copy your **API key** and **API secret**.\n",
    "- Scroll down and click **Create my access token**, and copy your **Access token** and **Access token secret**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rhspWXVGKlRU"
   },
   "source": [
    "# Connecting to Twitter Streaming API and Download Data using `Tweepy`\n",
    "\n",
    "We will be using a Python library called **Tweepy** to connect to **Twitter Streaming API** and downloading the data. If you don't have Tweepy installed in your machine, go to this link ([github.com/tweepy/tweepy](https://github.com/tweepy/tweepy)), and follow the installation instructions.\n",
    "\n",
    "To install, simply launch **Terminal** and type:\n",
    "- pip install tweepy \n",
    "- **[or]** sudo pip install tweepy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter_secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qa6sW6YyKlRV"
   },
   "outputs": [],
   "source": [
    "# Variables that contains the user credentials to access Twitter API \n",
    "access_token = twitter_secrets.ACCESS_TOKEN    \n",
    "access_token_secret = twitter_secrets.ACCESS_TOKEN_SECRET  \n",
    "consumer_key = twitter_secrets.API_KEY                           \n",
    "consumer_secret = twitter_secrets.API_SECRET  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rrD_ZaifKlRY"
   },
   "source": [
    "# Twitter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZIH1i5ZKlRZ"
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pprint\n",
    "import json\n",
    "from tweepy import OAuthHandler\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "client = tweepy.Client(bearer_token=twitter_secrets.BEARER_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRJX46msKlRa"
   },
   "outputs": [],
   "source": [
    "results = client.search_recent_tweets(query='news', tweet_fields=['context_annotations', 'created_at'], max_results=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseIntoJson(tweet):\n",
    "    jsonForm = {\n",
    "        'author_id': tweet.author_id,\n",
    "        'context_annotations': tweet.context_annotations,\n",
    "        'conversation_id': tweet.conversation_id,\n",
    "        'created_at': tweet.created_at,\n",
    "        'data': tweet.data,\n",
    "        'id': tweet.id,\n",
    "        'in_reply_to_user_id': tweet.in_reply_to_user_id,\n",
    "        'keys': tweet.keys,\n",
    "        'text': tweet.text,\n",
    "        'public_metrics': tweet.public_metrics,\n",
    "        'values': tweet.values, # May not be relevant. Similar to keys\n",
    "    }\n",
    "    return jsonForm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author_id': None,\n",
      " 'context_annotations': [{'domain': {'description': 'Named people in the world '\n",
      "                                                    'like Nelson Mandela',\n",
      "                                     'id': '10',\n",
      "                                     'name': 'Person'},\n",
      "                          'entity': {'description': 'Hiroshi Kamiya (Á•ûË∞∑Êµ©Âè≤)',\n",
      "                                     'id': '1129394002392784896',\n",
      "                                     'name': 'Hiroshi Kamiya'}},\n",
      "                         {'domain': {'description': 'Named people in the world '\n",
      "                                                    'like Nelson Mandela',\n",
      "                                     'id': '10',\n",
      "                                     'name': 'Person'},\n",
      "                          'entity': {'description': 'Japanese Voice Actor',\n",
      "                                     'id': '1161360318783619072',\n",
      "                                     'name': 'Daisuke Ono'}},\n",
      "                         {'domain': {'description': 'An actor or actress in '\n",
      "                                                    'the world, like Kate '\n",
      "                                                    'Winslet or Leonardo '\n",
      "                                                    'DiCaprio',\n",
      "                                     'id': '56',\n",
      "                                     'name': 'Actor'},\n",
      "                          'entity': {'description': 'Hiroshi Kamiya (Á•ûË∞∑Êµ©Âè≤)',\n",
      "                                     'id': '1129394002392784896',\n",
      "                                     'name': 'Hiroshi Kamiya'}},\n",
      "                         {'domain': {'description': 'An actor or actress in '\n",
      "                                                    'the world, like Kate '\n",
      "                                                    'Winslet or Leonardo '\n",
      "                                                    'DiCaprio',\n",
      "                                     'id': '56',\n",
      "                                     'name': 'Actor'},\n",
      "                          'entity': {'description': 'Japanese Voice Actor',\n",
      "                                     'id': '1161360318783619072',\n",
      "                                     'name': 'Daisuke Ono'}},\n",
      "                         {'domain': {'description': 'Top level interests and '\n",
      "                                                    'hobbies groupings, like '\n",
      "                                                    'Food or Travel',\n",
      "                                     'id': '65',\n",
      "                                     'name': 'Interests and Hobbies Vertical'},\n",
      "                          'entity': {'description': 'Hobbies and interests',\n",
      "                                     'id': '847868745150119936',\n",
      "                                     'name': 'Home & family'}},\n",
      "                         {'domain': {'description': 'A grouping of interests '\n",
      "                                                    'and hobbies entities, '\n",
      "                                                    'like Novelty Food or '\n",
      "                                                    'Destinations',\n",
      "                                     'id': '66',\n",
      "                                     'name': 'Interests and Hobbies Category'},\n",
      "                          'entity': {'description': 'Talk radio',\n",
      "                                     'id': '847527324043968512',\n",
      "                                     'name': 'Talk radio'}}],\n",
      " 'conversation_id': None,\n",
      " 'created_at': datetime.datetime(2022, 1, 28, 9, 16, 39, tzinfo=datetime.timezone.utc),\n",
      " 'data': {'context_annotations': [{'domain': {'description': 'Named people in '\n",
      "                                                             'the world like '\n",
      "                                                             'Nelson Mandela',\n",
      "                                              'id': '10',\n",
      "                                              'name': 'Person'},\n",
      "                                   'entity': {'description': 'Hiroshi Kamiya '\n",
      "                                                             '(Á•ûË∞∑Êµ©Âè≤)',\n",
      "                                              'id': '1129394002392784896',\n",
      "                                              'name': 'Hiroshi Kamiya'}},\n",
      "                                  {'domain': {'description': 'Named people in '\n",
      "                                                             'the world like '\n",
      "                                                             'Nelson Mandela',\n",
      "                                              'id': '10',\n",
      "                                              'name': 'Person'},\n",
      "                                   'entity': {'description': 'Japanese Voice '\n",
      "                                                             'Actor',\n",
      "                                              'id': '1161360318783619072',\n",
      "                                              'name': 'Daisuke Ono'}},\n",
      "                                  {'domain': {'description': 'An actor or '\n",
      "                                                             'actress in the '\n",
      "                                                             'world, like Kate '\n",
      "                                                             'Winslet or '\n",
      "                                                             'Leonardo '\n",
      "                                                             'DiCaprio',\n",
      "                                              'id': '56',\n",
      "                                              'name': 'Actor'},\n",
      "                                   'entity': {'description': 'Hiroshi Kamiya '\n",
      "                                                             '(Á•ûË∞∑Êµ©Âè≤)',\n",
      "                                              'id': '1129394002392784896',\n",
      "                                              'name': 'Hiroshi Kamiya'}},\n",
      "                                  {'domain': {'description': 'An actor or '\n",
      "                                                             'actress in the '\n",
      "                                                             'world, like Kate '\n",
      "                                                             'Winslet or '\n",
      "                                                             'Leonardo '\n",
      "                                                             'DiCaprio',\n",
      "                                              'id': '56',\n",
      "                                              'name': 'Actor'},\n",
      "                                   'entity': {'description': 'Japanese Voice '\n",
      "                                                             'Actor',\n",
      "                                              'id': '1161360318783619072',\n",
      "                                              'name': 'Daisuke Ono'}},\n",
      "                                  {'domain': {'description': 'Top level '\n",
      "                                                             'interests and '\n",
      "                                                             'hobbies '\n",
      "                                                             'groupings, like '\n",
      "                                                             'Food or Travel',\n",
      "                                              'id': '65',\n",
      "                                              'name': 'Interests and Hobbies '\n",
      "                                                      'Vertical'},\n",
      "                                   'entity': {'description': 'Hobbies and '\n",
      "                                                             'interests',\n",
      "                                              'id': '847868745150119936',\n",
      "                                              'name': 'Home & family'}},\n",
      "                                  {'domain': {'description': 'A grouping of '\n",
      "                                                             'interests and '\n",
      "                                                             'hobbies '\n",
      "                                                             'entities, like '\n",
      "                                                             'Novelty Food or '\n",
      "                                                             'Destinations',\n",
      "                                              'id': '66',\n",
      "                                              'name': 'Interests and Hobbies '\n",
      "                                                      'Category'},\n",
      "                                   'entity': {'description': 'Talk radio',\n",
      "                                              'id': '847527324043968512',\n",
      "                                              'name': 'Talk radio'}}],\n",
      "          'created_at': '2022-01-28T09:16:39.000Z',\n",
      "          'id': '1486991603625754627',\n",
      "          'text': 'RT @animatetimes: „Äê„äó #Á•ûË∞∑Êµ©Âè≤ „Åï„Çì„ÅäË™ïÁîüÊó•Ë®òÂøµüéâ„ÄëÁ•ûË∞∑Êµ©Âè≤„Åï„Çì„ÄÅ#Â∞èÈáéÂ§ßËºî '\n",
      "                  '„Åï„Çì„Å´„Çà„Çã„É©„Ç∏„Ç™Áï™ÁµÑÁô∫„ÄéDGS VS MOB LIVE '\n",
      "                  'SURVIVE„Äè„ÅåÈñãÂÇ¨ÔºÅ2„Ç∞„É´„Éº„Éó„ÅÆÊà¶„ÅÑ„ÅÆË®òÈå≤„Çí„Åì„Åì„Å´Ë®ò„Åô!!Ôºè„É©„Ç§„Éñ„É¨„Éù„Éº„Éà #dgs #mob '\n",
      "                  'https://t.c‚Ä¶'},\n",
      " 'id': 1486991603625754627,\n",
      " 'in_reply_to_user_id': None,\n",
      " 'keys': <bound method Mapping.keys of <Tweet id=1486991603625754627 text=RT @animatetimes: „Äê„äó #Á•ûË∞∑Êµ©Âè≤ „Åï„Çì„ÅäË™ïÁîüÊó•Ë®òÂøµüéâ„ÄëÁ•ûË∞∑Êµ©Âè≤„Åï„Çì„ÄÅ#Â∞èÈáéÂ§ßËºî „Åï„Çì„Å´„Çà„Çã„É©„Ç∏„Ç™Áï™ÁµÑÁô∫„ÄéDGS VS MOB LIVE SURVIVE„Äè„ÅåÈñãÂÇ¨ÔºÅ2„Ç∞„É´„Éº„Éó„ÅÆÊà¶„ÅÑ„ÅÆË®òÈå≤„Çí„Åì„Åì„Å´Ë®ò„Åô!!Ôºè„É©„Ç§„Éñ„É¨„Éù„Éº„Éà #dgs #mob https://t.c‚Ä¶>>,\n",
      " 'public_metrics': None,\n",
      " 'text': 'RT @animatetimes: „Äê„äó #Á•ûË∞∑Êµ©Âè≤ „Åï„Çì„ÅäË™ïÁîüÊó•Ë®òÂøµüéâ„ÄëÁ•ûË∞∑Êµ©Âè≤„Åï„Çì„ÄÅ#Â∞èÈáéÂ§ßËºî „Åï„Çì„Å´„Çà„Çã„É©„Ç∏„Ç™Áï™ÁµÑÁô∫„ÄéDGS VS '\n",
      "         'MOB LIVE SURVIVE„Äè„ÅåÈñãÂÇ¨ÔºÅ2„Ç∞„É´„Éº„Éó„ÅÆÊà¶„ÅÑ„ÅÆË®òÈå≤„Çí„Åì„Åì„Å´Ë®ò„Åô!!Ôºè„É©„Ç§„Éñ„É¨„Éù„Éº„Éà #dgs #mob '\n",
      "         'https://t.c‚Ä¶',\n",
      " 'values': <bound method Mapping.values of <Tweet id=1486991603625754627 text=RT @animatetimes: „Äê„äó #Á•ûË∞∑Êµ©Âè≤ „Åï„Çì„ÅäË™ïÁîüÊó•Ë®òÂøµüéâ„ÄëÁ•ûË∞∑Êµ©Âè≤„Åï„Çì„ÄÅ#Â∞èÈáéÂ§ßËºî „Åï„Çì„Å´„Çà„Çã„É©„Ç∏„Ç™Áï™ÁµÑÁô∫„ÄéDGS VS MOB LIVE SURVIVE„Äè„ÅåÈñãÂÇ¨ÔºÅ2„Ç∞„É´„Éº„Éó„ÅÆÊà¶„ÅÑ„ÅÆË®òÈå≤„Çí„Åì„Åì„Å´Ë®ò„Åô!!Ôºè„É©„Ç§„Éñ„É¨„Éù„Éº„Éà #dgs #mob https://t.c‚Ä¶>>}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(parseIntoJson(results.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(data=[<Tweet id=1486991603625754627 text=RT @animatetimes: „Äê„äó #Á•ûË∞∑Êµ©Âè≤ „Åï„Çì„ÅäË™ïÁîüÊó•Ë®òÂøµüéâ„ÄëÁ•ûË∞∑Êµ©Âè≤„Åï„Çì„ÄÅ#Â∞èÈáéÂ§ßËºî „Åï„Çì„Å´„Çà„Çã„É©„Ç∏„Ç™Áï™ÁµÑÁô∫„ÄéDGS VS MOB LIVE SURVIVE„Äè„ÅåÈñãÂÇ¨ÔºÅ2„Ç∞„É´„Éº„Éó„ÅÆÊà¶„ÅÑ„ÅÆË®òÈå≤„Çí„Åì„Åì„Å´Ë®ò„Åô!!Ôºè„É©„Ç§„Éñ„É¨„Éù„Éº„Éà #dgs #mob https://t.c‚Ä¶>, <Tweet id=1486991603558678528 text=RT @gundam_info: „ÄåGUNDAM FACTORY YOKOHAMA„Äç2023Âπ¥3Êúà31Êó•„Åæ„ÅßÊúüÈñìÂª∂Èï∑Ê±∫ÂÆöÔºÅ https://t.co/CINkD5QQTI>, <Tweet id=1486991603558674437 text=@Sankei_news „Åì„ÅÆ„Çà„ÅÜ„Å™„Éã„É•„Éº„Çπ„Åå‰∏ÄÁï™Â´å„Å†‚Ä¶\n",
       "ÂèØÂìÄÊÉ≥„Å´‚Ä¶\n",
       "Â§©ÂõΩ„Åß„Åü„Åè„Åï„ÇìÈ£ü„Åπ„Å¶ÈÅä„Çì„Åß„Å≠„ÄÇ>, <Tweet id=1486991603449225216 text=RT @lanei_: https://t.co/sy4WFOnuFk\n",
       "\n",
       "ÎØºÏ£ºÎãπÏÑú Ïù¥Îû¨ÏúºÎ©¥ Î≤åÏç® [ÎØºÏ£ºÎãπÎßåÎπºÍ≥†] ÏãúÏ¶å2 Î∞úÎ∞úÌñàÏùÑÌÖêÎç∞.. Ï°∞Ïö©ÌïòÎÑ§ „Öã„Öã>, <Tweet id=1486991603353161731 text=RT @HuaweiFactsJP: üì¢Êó•Êõú„Åæ„Åß„Åß„Åô‚ö†\n",
       "Ôºº#„Éï„Ç°„Éº„Ç¶„Çß„Ç§„Åã„Çâ„ÅäÂπ¥Áéâüßß„äóÔºè\n",
       "\n",
       "#amazon„ÇÆ„Éï„ÉàÂà∏ „Ää1Á≠âü•á1‰∏áÂÜÜÂàÜ„ÄÅ2Á≠âü•à5ÂçÉÂÜÜÂàÜ„Äã„ÅåÂΩì„Åü„Çã„Éó„É¨„Çº„É≥„Éà„Ç≠„É£„É≥„Éö„Éº„É≥üéÅ\n",
       "ÊÆã„Çä3Êó•‚ùóÔ∏è‚ùóÔ∏è\n",
       "\n",
       "‚úÖÂøúÂãüÊñπÊ≥ï\n",
       "‚ë†ÂÖ¨Âºè@HuaweiFactsJP„Çí„Éï„Ç©„É≠„Éº\n",
       "‚ë°Âõ∫ÂÆö„ÉÑ„Ç§„Éº„Éà„Çí‚Ä¶>, <Tweet id=1486991603327807495 text=RT @shahsabg: welcome #news of record exports from #Pakistan to #China ,#Beijing #ready to enhance #trade #economic cooperation #Islamabad,‚Ä¶>, <Tweet id=1486991603277316100 text=RT @comic_natalie: „Äå„Ç∑„É≥„Ç´„É™„Ç™„É≥Z„Äç„Åå„Éè„ÉÉ„Éî„Éº„Çª„ÉÉ„Éà„Å´ÂàùÁôªÂ†¥„ÄÅÈÉ®ÂìÅ„Çí‰ªò„ÅëÊõø„Åà„Å¶„Ç™„É™„Ç∏„Éä„É´Ê©ü‰Ωì‰Ωú„Çå„Çã\n",
       "https://t.co/dLzn7j1fYT\n",
       "\n",
       "#„Ç∑„É≥„Ç´„É™„Ç™„É≥Z https://t.co/RlOpIUW5eL>, <Tweet id=1486991603277303808 text=‰ΩêÊ∏°ÈáëÂ±±„ÄÄ‰∏ÄËª¢„ÄÅ‰∏ñÁïåÈÅ∫Áî£Êé®Ëñ¶„Å∏ https://t.co/XCYdjPWK2F @Sankei_news„Çà„Çä \n",
       "\n",
       "„ÅÑ„Åæ‰∏ñÁïåÈÅ∫Áî£„Å´Ë™çÂÆö„Åï„Çå„Å¶„ÇÇ\n",
       "„Ç≥„É≠„Éä„ÅÆ„Åõ„ÅÑ„ÅßË°å„Åë„Å™„Åè„Å¶\n",
       "ÁßªÂãïÂà∂Èôê„Åå„Å™„Åè„Å™„Å£„Åü„Åì„Çç„Å´„ÅØ\n",
       "‰∏ñÁïåÈÅ∫Áî£„Å´Ë™çÂÆö„Åï„Çå„ÅüÁÜ±„Åå„ÄÅÂÜ∑„ÇÅÂßã„ÇÅ„Å¶„ÅÑ„Çã„Å†„Çç„ÅÜ„Åã„Çâ\n",
       "„Ç≥„É≠„Éä„ÅåËêΩ„Å°ÁùÄ„ÅÑ„Å¶„Åã„Çâ\n",
       "Ë™çÂÆö„Åï„Çå„ÅüÊñπ„ÅåËâØ„ÅÑ„Å®ÊÄù„ÅÜ„Çì„Å†„Çà„Å≠>, <Tweet id=1486991603118092289 text=RT @a_meluzzi: Green pass illegittimo, Avv. Sinagra: \"Giudice accoglie miei ricorsi e convoca Brusaferro e Bassetti\" - Secondo Piano News h‚Ä¶>, <Tweet id=1486991603109666818 text=RT @Krishnavi21: Jab tak Salman Khan announce na kare, don't believe on any voting poll, khabri, news whatsoever. Please don't even check v‚Ä¶>, <Tweet id=1486991602979590147 text=RT @BBCWorld: What does Kim Jong-un want from North Korea missile tests? https://t.co/0KfUY3wFPU>, <Tweet id=1486991602962743300 text=MAMADOU NDIAYE: \"#SAMBO HAS EVERY CHANCE TO GET INTO THE PROGRAM OF THE OLYMPIC GAMES\"\n",
       "Read more: https://t.co/u1SpDbzcqQ https://t.co/UhjULhyEoL>, <Tweet id=1486991602904010753 text=RT @RiverMojave: Dear #Afghan friends. We understand the panic over the flight that left from Kabul today. It is great news that the USG wa‚Ä¶>, <Tweet id=1486991602845421568 text=PENTAGON(ÌéúÌÉÄÍ≥§) ‚Äì Feelin Like (Music Bank) | KBS WORLD TV¬†220128 https://t.co/ROOvy5hjPx https://t.co/bN4kriMO4P>, <Tweet id=1486991602799489029 text=RT @nhk_news: „ÄêÈÄüÂ†± JUST IN „ÄëÂÖ®ÂõΩ„ÅÆÊñ∞Âûã„Ç≥„É≠„ÉäÊÑüÊüìÁ¢∫Ë™ç Âàù„ÅÆ8‰∏á‰∫∫Ë∂Ö ÈÅéÂéªÊúÄÂ§ö„Å´ #nhk_news https://t.co/ZM38WdLi5u>, <Tweet id=1486991602623070210 text=RT @tsargradtv: –ü–µ—Ä–µ–µ—Ö–∞–≤—à–∏–π –≤ –°–®–ê –∂–∏—Ç–µ–ª—å –§—Ä–∞–Ω—Ü–∏–∏ –∑–∞—è–≤–∏–ª, —á—Ç–æ –æ–∫–∞–∑–∞–ª—Å—è –≤ —Å—Ç—Ä–∞–Ω–µ —Ç—Ä–µ—Ç—å–µ–≥–æ –º–∏—Ä–∞. –°—Ç–æ–∏–ª–æ –ª–∏—à—å –æ–¥–∏–Ω —Ä–∞–∑ —Å—Ö–æ–¥–∏—Ç—å –Ω–∞ –ø–æ—á—Ç—É, —á—Ç–æ–±—ã‚Ä¶>, <Tweet id=1486991602543378432 text=RT @2tweetaboutit: Three sought in connection with stabbing on bus in Ealing https://t.co/3YR2jbm39s>, <Tweet id=1486991602379890688 text=RT @sinach: I know what the news said\n",
       "I know what the economy said \n",
       "I know what the doctor said \n",
       "I know what the experts said \n",
       "But, have yo‚Ä¶>, <Tweet id=1486991602333765634 text=JINJIN(ÏßÑÏßÑ) &amp; ROCKY(ÎùºÌÇ§) (ASTRO) ‚Äì Just Breath(Ïà® Ï¢Ä Ïâ¨Ïûê) (Music Bank) | KBS WORLD TV¬†220128 https://t.co/ROOvy5hjPx https://t.co/KSLMUhWmrP>, <Tweet id=1486991602266808320 text=RT @J_League: üèÜ#Ôº™„É™„Éº„Ç∞„Éû„Çπ„Ç≥„ÉÉ„ÉàÁ∑èÈÅ∏Êåô2022üèÜ\n",
       "‚ú®‰∏≠ÈñìÁô∫Ë°®‚ú®\n",
       "\n",
       "1‰Ωç #„Éû„É™„Éé„ÇπÂêõ @prompt_fmarinos \n",
       "2‰Ωç #„É¥„Ç£„É¥„Ç£„Åè„Çì @v_varenstaff \n",
       "3‰Ωç #„Ç∞„É©„É≥„Éë„Çπ„Åè„Çì @grampuskun_No1 \n",
       "\n",
       "ÊäïÁ•®Á∑†„ÇÅÂàá„Çä„ÅØ2/4(Èáë)‚Ä¶>], includes={}, errors=[], meta={'newest_id': '1486991603625754627', 'oldest_id': '1486991602266808320', 'result_count': 20, 'next_token': 'b26v89c19zqg8o3fpe47newtsnd3aoyst8f4mdjevtwfx'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LNSFH8cQKlRd"
   },
   "outputs": [],
   "source": [
    "# Convert a result to JSON with \"._json\"\n",
    "# print(type(results))\n",
    "# #print(results._json)\n",
    "# print(results.data)\n",
    "# print(type(results._json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_t5L-ssNKlRh"
   },
   "outputs": [],
   "source": [
    "# Convert all the results into a `list of dictionaries`\n",
    "list_of_status_dicts = [parseIntoJson(res) for res in results.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "av1hvfhCKlRj"
   },
   "outputs": [],
   "source": [
    "# This code is the same as the code in the cell above, just that it's shorter.\n",
    "# [Python list comprehension] Convert all the results into a `list of dictionaries`\n",
    "# list_of_status_dicts = [result._json for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACje5rW2KlRl",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_status_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xnNR6DtSKlRo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['author_id', 'context_annotations', 'conversation_id', 'created_at', 'data', 'id', 'in_reply_to_user_id', 'keys', 'text', 'public_metrics', 'values'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_status_dicts[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bj0mbw56KlRr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @animatetimes: „Äê„äó #Á•ûË∞∑Êµ©Âè≤ „Åï„Çì„ÅäË™ïÁîüÊó•Ë®òÂøµüéâ„ÄëÁ•ûË∞∑Êµ©Âè≤„Åï„Çì„ÄÅ#Â∞èÈáéÂ§ßËºî „Åï„Çì„Å´„Çà„Çã„É©„Ç∏„Ç™Áï™ÁµÑÁô∫„ÄéDGS VS MOB LIVE SURVIVE„Äè„ÅåÈñãÂÇ¨ÔºÅ2„Ç∞„É´„Éº„Éó„ÅÆÊà¶„ÅÑ„ÅÆË®òÈå≤„Çí„Åì„Åì„Å´Ë®ò„Åô!!Ôºè„É©„Ç§„Éñ„É¨„Éù„Éº„Éà #dgs #mob https://t.c‚Ä¶'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_status_dicts[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bKJPY3VNKlRt"
   },
   "source": [
    "# Twitter Search (Advance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y95y10oUKlRu"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "search_all_tweets() missing 1 required positional argument: 'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-6f9056e4e847>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_tweets\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearched_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnew_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_all_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_id\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnew_tweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: search_all_tweets() missing 1 required positional argument: 'query'"
     ]
    }
   ],
   "source": [
    "query = 'trump'\n",
    "max_tweets = 555\n",
    "\n",
    "searched_tweets = []\n",
    "last_id = -1\n",
    "while len(searched_tweets) < max_tweets:\n",
    "    count = max_tweets - len(searched_tweets)\n",
    "    try:\n",
    "        new_tweets = client.search_all_tweets(query=query, lang='en', count=count, max_id=str(last_id - 1))\n",
    "        if not new_tweets:\n",
    "            break\n",
    "        searched_tweets.extend(new_tweets)\n",
    "        last_id = new_tweets[-1].id\n",
    "    except tweepy.errors.TweepyException as e:\n",
    "        # Depending on TweepError.code, one may want to retry or wait\n",
    "        # to keep things simple, we will give up on an error\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSPi5-82KlRw"
   },
   "outputs": [],
   "source": [
    "len(searched_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8K_E3z94KlR0"
   },
   "outputs": [],
   "source": [
    "# Convert all the results into a `list of dictionaries`\n",
    "list_of_status_dicts_2 = [x._json for x in searched_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1RfjEqywKlR2"
   },
   "outputs": [],
   "source": [
    "len(list_of_status_dicts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VruiBKEdKlR5"
   },
   "outputs": [],
   "source": [
    "list_of_status_dicts_2[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "irDAGfXdKlR8"
   },
   "source": [
    "# Twitter Streaming\n",
    "\n",
    "The Streaming APIs give developers low latency access to Twitter‚Äôs global stream of Tweet data. A proper implementation of a streaming client will be pushed messages indicating Tweets and other events have occurred, without any of the overhead associated with polling a REST endpoint.\n",
    "\n",
    "More info: https://dev.twitter.com/streaming/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NfrRcFWMZ9W"
   },
   "outputs": [],
   "source": [
    "# mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZS-A2G0jMtF3"
   },
   "outputs": [],
   "source": [
    "path = '/content/drive/My Drive/BT4222/twitter_streaming_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-EP5teeM56i"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9A1eMJLKlR8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "\n",
    "# This is a basic listener that just prints received tweets to stdout.\n",
    "class StdOutListener(StreamListener):\n",
    "\n",
    "    def on_data(self, json_data):\n",
    "        # print(json_data)\n",
    "        filename = re.sub(r'\\s|\\/|:', r'_', '%s.txt' % str(datetime.now()))\n",
    "        # fileloc = './twitter_stream_data/' + filename\n",
    "        fileloc = os.path.join(path, filename)\n",
    "  \n",
    "        # 1% chance of printing out the file location\n",
    "        if random.randint(0, 100) == 0:\n",
    "            print(fileloc)\n",
    "        # End of if statement.\n",
    "            \n",
    "        with open(fileloc, 'w') as f:\n",
    "            f.write(json_data)\n",
    "        return True\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "    l = StdOutListener()\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    stream = Stream(auth, l)\n",
    "\n",
    "    # This line filter Twitter Streams to capture data by the keywords: 'python', 'javascript', 'ruby'\n",
    "    stream.filter(track=['obama', 'trump', 'clinton'])\n",
    "\n",
    "\"\"\"\n",
    "Note that this is a while loop! It runs until the cows come home!\n",
    "To terminate this infinite loop, press the stop button in the iPython notebook's TOOLBAR.\n",
    "\n",
    "You will see a \"KeyboardInterrupt\" error message -- which is what you are supposed to get.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "In0Mjc8WKlR_"
   },
   "source": [
    "### You should see the files in the `twitter_stream_data` folder\n",
    "\n",
    "![](./images/twitter_stream_data_folder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JMfzhASvKlSA"
   },
   "source": [
    "# Reading Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vV9ZVRg7KlSB"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "# list_of_files = (glob.glob(\"./twitter_stream_data/*.txt\"))\n",
    "list_of_files = (glob.glob(\"/content/drive/My Drive/BT4222/twitter_data/*txt\"))\n",
    "len(list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pj6L63CsKlSC"
   },
   "outputs": [],
   "source": [
    "# Read all the TXT files into a \"list of dictionary objects\" called \"tweets_data\"\n",
    "\n",
    "tweets_data = []\n",
    "\n",
    "for fname in list_of_files:\n",
    "    tweets_file = open(fname, \"r\")\n",
    "    for line in tweets_file:\n",
    "        try:\n",
    "            tweet = json.loads(line)\n",
    "            tweets_data.append(tweet)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "62t8mNVhKlSE"
   },
   "source": [
    "We can print the number of tweets using the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fLMTDgF8KlSF"
   },
   "outputs": [],
   "source": [
    "len(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P6NSfIDXKlSI"
   },
   "outputs": [],
   "source": [
    "tweets_data[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OKO405xBKlSL"
   },
   "source": [
    "Next, we will structure the tweets data into a pandas DataFrame to simplify the data manipulation. We will start by creating an empty DataFrame called tweets using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwl1rxuVKlSL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweets = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-VoFpLazKlSN"
   },
   "source": [
    "Next, we will add 3 columns to the tweets DataFrame called text, lang, and country. text column contains the tweet, lang column contains the language in which the tweet was written, and country the country from which the tweet was sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8H1l_NMFKlSN"
   },
   "outputs": [],
   "source": [
    "tweets['text'] = list(map(lambda tweet: tweet['text'] if 'text' in tweet else None, tweets_data))\n",
    "tweets['lang'] = list(map(lambda tweet: tweet['lang'] if 'lang' in tweet else None, tweets_data))\n",
    "tweets['country'] = list(map(lambda tweet: tweet['place']['country'] if ('place' in tweet and (tweet['place'] != None)) else None, tweets_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RLc4w-QCKlSQ"
   },
   "source": [
    "Preview the **tweets** DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pzegy7kdKlSR"
   },
   "outputs": [],
   "source": [
    "tweets.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GnsaZU-oKlST"
   },
   "outputs": [],
   "source": [
    "tweets[  tweets['country'].notnull()  ].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9DtnW4W2KlSV"
   },
   "source": [
    "### Top 5 languages and Top 5 countries\n",
    "\n",
    "Next, we will create 2 charts: The first one describing the Top 5 languages in which the tweets were written, and the second the Top 5 countries from which the tweets were sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9iC_1Yw-KlSW"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "tweets_by_lang = tweets['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bfoMnCL1KlSZ"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=10)\n",
    "ax.set_xlabel('Languages', fontsize=15)\n",
    "ax.set_ylabel('Number of tweets' , fontsize=15)\n",
    "ax.set_title('Top 5 languages', fontsize=15, fontweight='bold')\n",
    "tweets_by_lang[:5].plot(ax=ax, kind='bar', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWWOxKtfKlSb"
   },
   "outputs": [],
   "source": [
    "tweets_by_country = tweets['country'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=10)\n",
    "ax.set_xlabel('Countries', fontsize=15)\n",
    "ax.set_ylabel('Number of tweets' , fontsize=15)\n",
    "ax.set_title('Top 5 countries', fontsize=15, fontweight='bold')\n",
    "tweets_by_country[:5].plot(ax=ax, kind='bar', color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "tnX8sFAeKlSf"
   },
   "source": [
    "# Mining the Tweets\n",
    "\n",
    "Our main goals in these text mining tasks are: compare the popularity of Obama, Trump and Clinton and to retrieve links. We will do the following steps:\n",
    "\n",
    "- We will add tags to our tweets DataFrame in order to be able to manipualte the data easily.\n",
    "- Extract links from tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cb8scXmIKlSg"
   },
   "source": [
    "First, we will create a function that checks if a specific keyword is present in a text. We will do this by using regular expressions. Python provides a library for regular expression called re. We will start by importing this library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fUpR8QreKlSg"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5dPM7pKgKlSi"
   },
   "source": [
    "Next we will create a function called word_in_text(word, text). This function return True if a word is found in text, otherwise it returns False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4dFwbGRKlSj"
   },
   "outputs": [],
   "source": [
    "def word_in_text(word, text):\n",
    "    if word and text:\n",
    "        word = word.lower()\n",
    "        text = text.lower()\n",
    "        match = re.search(word, text)\n",
    "        if match:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xe419ohDKlSk"
   },
   "source": [
    "Next, we will add 3 columns to our tweets DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oXfbJcTAKlSl"
   },
   "outputs": [],
   "source": [
    "tweets['obama'] = tweets['text'].apply(lambda tweet: word_in_text('obama', tweet))\n",
    "tweets['trump'] = tweets['text'].apply(lambda tweet: word_in_text('trump', tweet))\n",
    "tweets['clinton'] = tweets['text'].apply(lambda tweet: word_in_text('clinton', tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QIYu0-uTKlSm"
   },
   "source": [
    "The modified DataFrame looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X9ZzEqn_KlSn"
   },
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "16eKylUYKlSp"
   },
   "source": [
    "We can calculate the number of tweets for each person as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jdNInDp0KlSq"
   },
   "outputs": [],
   "source": [
    "print(tweets['obama'].value_counts()[True])\n",
    "print(tweets['trump'].value_counts()[True])\n",
    "print(tweets['clinton'].value_counts()[True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zcg6yILwKlSw"
   },
   "source": [
    "We can make a simple comparaison chart by executing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wn2mzODwKlSw"
   },
   "outputs": [],
   "source": [
    "politicians = ['obama', 'trump', 'clinton']\n",
    "tweets_by_politicians = [tweets['obama'].value_counts()[True], tweets['trump'].value_counts()[True], tweets['clinton'].value_counts()[True]]\n",
    "\n",
    "x_pos = list(range(len(politicians)))\n",
    "width = 0.8\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x_pos, tweets_by_politicians, width, alpha=1, color='g')\n",
    "\n",
    "# Setting axis labels and ticks\n",
    "ax.set_ylabel('Number of tweets', fontsize=15)\n",
    "ax.set_title('Ranking: Obama vs. Trump vs. Clinton', fontsize=10, fontweight='bold')\n",
    "ax.set_xticks([p + 0.4 * width for p in x_pos])\n",
    "ax.set_xticklabels(politicians)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dcZSlPKsKlS0"
   },
   "source": [
    "# Extracting links from the tweets\n",
    "\n",
    "Now, we want to retrieve links in the tweets. We will start by creating a function that uses regular expressions for retrieving link that start with **\"http://\"** or **\"https://\"** from a text. This function will return the url if found, otherwise it returns an empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BKaRb0P0KlS1"
   },
   "outputs": [],
   "source": [
    "def extract_link(text):\n",
    "    try:\n",
    "        regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "        match = re.search(regex, text)\n",
    "        if match:\n",
    "            return match.group()\n",
    "        return ''\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4aXG2IiiKlS2"
   },
   "source": [
    "Next, we will add a column called link to our tweets DataFrame. This column will contain the urls information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_wKIU8XLKlS2"
   },
   "outputs": [],
   "source": [
    "tweets['link'] = tweets['text'].apply(lambda tweet: extract_link(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "riDCaiTeKlS4"
   },
   "source": [
    "The modified DataFrame looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbj9J53zKlS6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MCgxFscLKlS8"
   },
   "outputs": [],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NorUIPWOKlS_"
   },
   "source": [
    "Next, we will create a new DataFrame called **tweets_with_link**. \n",
    "This DataFrame is a subset of tweets DataFrame and contains all tweets that have a link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3yIiZJMrKlS_"
   },
   "outputs": [],
   "source": [
    "tweets_with_link = tweets[ tweets['link'] != ''].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8etrEi-ZKlTC"
   },
   "outputs": [],
   "source": [
    "tweets_with_link.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cY5gNpyqKlTF"
   },
   "outputs": [],
   "source": [
    "tweets_with_link.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A58fc12yKlTH"
   },
   "source": [
    "We can now print out all links for **obama**, **trump**, and **clinton** by executing the commands below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sIOH6mUSKlTH",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(tweets_with_link[tweets_with_link['obama']   == True]['link'])\n",
    "print(tweets_with_link[tweets_with_link['trump']   == True]['link'])\n",
    "print(tweets_with_link[tweets_with_link['clinton'] == True]['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gmmx8JLaKlTJ"
   },
   "outputs": [],
   "source": [
    "# Now say we want to read one of the links above, https://t.co/oua32nXu8W\n",
    "\n",
    "# Read the HTML source of the URL: https://t.co/oua32nXu8W\n",
    "import urllib.request\n",
    "url = 'https://t.co/oua32nXu8W'\n",
    "request = urllib.request.Request(url)\n",
    "response = urllib.request.urlopen(request)\n",
    "html = response.read()\n",
    "try:\n",
    "    html = html.decode('utf-8')\n",
    "except:\n",
    "    html = html.decode('unicode_escape')\n",
    "\n",
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vgz8vo8EKlTM"
   },
   "outputs": [],
   "source": [
    "# See the title of the HTML document\n",
    "\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6M8PtvjKKlTP"
   },
   "outputs": [],
   "source": [
    "# Extract all the paragraphs (p) and print out the content\n",
    "\n",
    "for paragraph in soup.find_all('p'):\n",
    "    if paragraph.string is not None:\n",
    "        print(paragraph.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJ3seeqiKlTQ"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "In this tutorial, we covered many techniques used in text mining. The code here can be:\n",
    "1. modified to create a deeper analysis, or  \n",
    "2. adapted to another use case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OE57ugqVKlTR"
   },
   "source": [
    "# References\n",
    "- http://en.wikipedia.org/wiki/Text_mining\n",
    "- http://en.wikipedia.org/wiki/Word-sense_disambiguation\n",
    "- http://en.wikipedia.org/wiki/Regular_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "458ewyp3KlTR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A9U3OXv8KlTS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1TjuI8DqKlTT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fLXxjPwqKlTU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y75-tiGQKlTY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FceCet76KlTZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "02 Getting Data from Twitter.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
