{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "This notebook will be used for creating features from our collection of ESG reports, and publicly available data on market capitalisation \n",
    "\n",
    "\n",
    "## Approach taken:\n",
    "\n",
    "Respective sentiment scoring was calculated for each components of ESG using VADER's textual sentiment analysis package. To derive the sentiment score for each pillar, the keywords that best represent each pillar will be used to filter out the sentences that contain those keywords from the entire company's report. The sentences will be iterated through the function to generate a sentiment score, following which an aggregation will be made to generate the average sentiment score for a particular component of a given pillar in the company's report.\n",
    "\n",
    "\n",
    "To retrieve the market capitalisation values, we will be using yFinance api to scrape the data from Yahoo Finance. Following the retrieval of each market cap, currency conversion will be done to ensure that all market cap values are valued in the same denomination, before normalising the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kevintanyuejun/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/kevintanyuejun/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import os\n",
    "import fitz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import json\n",
    "import pprint\n",
    "import gensim\n",
    "import collections\n",
    "import spacy\n",
    "import gensim.corpora as corpora\n",
    "import nltk\n",
    "import tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from gensim.utils import simple_preprocess\n",
    "from textblob import TextBlob\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Read a pdf into a large string of text ---------------------------\n",
    "def read_pdf(file_path):\n",
    "    pymupdf_text = \"\"\n",
    "    with fitz.open(file_path) as doc:\n",
    "        for page in doc:\n",
    "            pymupdf_text += page.get_text()\n",
    "    return pymupdf_text\n",
    "\n",
    "\n",
    "# --------------------------- Read a report and breaks it up into individual sentences ---------------------------\n",
    "def convert_pdf_into_sentences(text):\n",
    "    # Remove unnecessary spaces and line breaks\n",
    "    text = re.sub(r'\\x0c\\x0c|\\x0c', \"\", str(text))\n",
    "    text = re.sub('\\n ', '', str(text))\n",
    "    text = re.sub('\\n', ' ', str(text))\n",
    "    text = ' '.join(text.split())\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    if \"”\" in text: text = text.replace(\".”\", \"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\", \"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\", \"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\", \"\\\"?\")\n",
    "    text = text.replace(\".\", \".<stop>\")\n",
    "    text = text.replace(\"?\", \"?<stop>\")\n",
    "    text = text.replace(\"!\", \"!<stop>\")\n",
    "    text = text.replace(\"<prd>\", \".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "\n",
    "    # Filter for sentences with more than 100 characters\n",
    "    sentences = [s.strip() for s in sentences if len(s) > 100]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# --------------------------- Retrieve the report name from the pdf ---------------------------\n",
    "def reportName(path):\n",
    "    name = path.split('/')[-1]\n",
    "    company = name.split('.')[0]\n",
    "    return company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the entire corpus of ESG/sustainability reports into a python dictionary, where the key - value pairs are of the following:\n",
    "\n",
    "    - key: Company name\n",
    "    - value: List containing all the sentences located in the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 468/468 [02:15<00:00,  3.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read our database of ESG reports\n",
    "path = 'Reports 2.0'\n",
    "esg_reports = glob.glob(path + '/*.pdf')\n",
    "esg_corpus = {}\n",
    "for report in tqdm.tqdm(esg_reports):\n",
    "    esg_corpus[reportName(report)] = convert_pdf_into_sentences(read_pdf(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the key words from our json file\n",
    "f = open('keywords.json')\n",
    "keywordBank = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following features will be created from the given corpus of report:\n",
    "\n",
    "    - Company name\n",
    "    - ESG Risk Score\n",
    "    - ESG Risk Rating\n",
    "    - Opportunities in Clean Tech Sentiment Score\n",
    "    - Carbon Emissions Sentiment Score\n",
    "    - Water Stress Sentiment Score\n",
    "    - Electronic Waste Sentiment Score\n",
    "    - Toxic Emissions & Waste Sentiment Score\t\n",
    "    - Human Capital Development Sentiment Score\t\n",
    "    - Privacy and Data Security Sentiment Score\n",
    "    - Labor Management Sentiment Score\t\n",
    "    - Governance Sentiment Score\t\n",
    "    - Market Capitalisation\t\n",
    "    - Page Count\t\n",
    "    - Sentence Count\t\n",
    "    - Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Sentiment Analysis ---------------------------\n",
    "# This function calculates the sentiment score for the various sentences using VADER\n",
    "# Sentence:\n",
    "#   - The sentence to be inputted to the function, which will return the respective sentiment score\n",
    "#   - If there are > 1 sentence, the average will be computed and returned\n",
    "def averagedCompoundSentimentScore(sentences):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    score = 0\n",
    "    for sentence in sentences:\n",
    "        sentiment = sid.polarity_scores(sentence)\n",
    "        score += sentiment['compound']\n",
    "    try:\n",
    "        return score / len(sentences)\n",
    "    except ZeroDivisionError:\n",
    "        return score\n",
    "\n",
    "# --------------------------- Sentence Extraction ---------------------------\n",
    "# This function extracts out the keywords from the given corpus\n",
    "# corpus: \n",
    "#   - This refers to a document (i.e one company)\n",
    "# subFeatureKeywords:\n",
    "#   - A list containing all the keywords which we would like to identify from our sentence bank\n",
    "def keySentences(corpus, subFeatureKeywords):\n",
    "    sentencesCaptured = []\n",
    "    for word in subFeatureKeywords:\n",
    "        sentencesCaptured.extend([sentence for sentence in corpus if word in sentence])\n",
    "    return sentencesCaptured\n",
    "\n",
    "# --------------------------- Print all sentences (Debugging purposes only) ---------------------------\n",
    "def printAllSentences(corpus, pillar, keywordBank):\n",
    "    for subFeature, kewords in keywordBank[pillar].items():\n",
    "        print('\\n\\n\\n')\n",
    "        print(f\"======= Printing Sentences from: '{subFeature}' =======\")\n",
    "        sentences = keySentences(corpus, kewords)\n",
    "        for sentence in sentences:\n",
    "            print(sentence)\n",
    "            print('\\n\\n')\n",
    "        \n",
    "# --------------------------- Subpillar Feature Statistics ---------------------------\n",
    "# 4 options for pillar: \n",
    "#   - 'Environment'\n",
    "#   - 'Social'\n",
    "#   - 'Governance'\n",
    "#   - 'ESG phrases'\n",
    "# corpus: \n",
    "#   - A specific company report, and NOT the whole collection of reports from all companies!\n",
    "# keywordBank: \n",
    "#   - All the keywords from the subpillar\n",
    "def subPillar_featureStats(corpus, pillar, keywordBank):\n",
    "    data = {}\n",
    "\n",
    "    # Calculate the sentences, frequency of sentence occurence, sentiment score etc\n",
    "    def summaryStatistics(corpus, subFeatureKeywords):\n",
    "        temp = {\n",
    "            # \"Sentences\": None,\n",
    "            \"NumOfSentences\": None,\n",
    "            \"FrequencyOfOccurence\": None,\n",
    "            \"SentimentScore\": None\n",
    "        }\n",
    "        # temp['Sentences'] = subpillar_sentences(corpus, keywordBank[pillar])\n",
    "        sentences = keySentences(corpus, subFeatureKeywords)\n",
    "        temp['NumOfSentences'] = len(sentences)\n",
    "        temp['FrequencyOfOccurence'] = round(len(sentences) / len(corpus), 5)\n",
    "        temp['SentimentScore'] = averagedCompoundSentimentScore(sentences)\n",
    "        return temp\n",
    "\n",
    "    for subFeature, subFeatureKeywords in keywordBank[pillar].items():\n",
    "        data[subFeature] = summaryStatistics(corpus, subFeatureKeywords)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# --------------------------- Complete Feature Statistics ---------------------------\n",
    "# This combines all the data across the 3 pillars into a dictionary \n",
    "# esg_bank:\n",
    "#   - Complete set of data processed from reading in all the companies\n",
    "#   - Structure of esg_bank:\n",
    "#       - Dictionary where\n",
    "#           - key: company name\n",
    "#           - value: [sentence1, sentence2, ..., sentenceN]\n",
    "# companyName:\n",
    "#   - The company we wish to explore\n",
    "# keywordBank:\n",
    "#   - Complete set of data from the keywords.json file\n",
    "def featureStats(esg_bank, companyName, keywordBank):\n",
    "    company = {\n",
    "        companyName: []\n",
    "    }\n",
    "    for pillar in [*keywordBank][:-1]:\n",
    "        temp = {}\n",
    "        temp[pillar] = subPillar_featureStats(esg_bank[companyName], pillar, keywordBank)\n",
    "        company[companyName].append(temp)\n",
    "    return company\n",
    "    \n",
    "def processByLength(esg_bank, keywordBank, numberOfReports):\n",
    "    companies = []\n",
    "\n",
    "    def flatten_data(dictionary_data):\n",
    "        new_data = {\n",
    "            \"Companies\": list(dictionary_data.keys())[0],\n",
    "        }\n",
    "        for subData in dictionary_data.values():\n",
    "            for i in range(0, 3):\n",
    "                for pillar, pillarValues in subData[i].items():\n",
    "                    for title, data in pillarValues.items():\n",
    "                        new_data[title + ' Sentiment Score'] = data['SentimentScore'] \n",
    "        return new_data\n",
    "\n",
    "    counter = 0\n",
    "    for company, data in tqdm.tqdm(esg_bank.items()):\n",
    "        if counter == numberOfReports:\n",
    "            break\n",
    "        else:\n",
    "            company_data = featureStats(esg_bank, company, keywordBank)\n",
    "            companies.append(flatten_data(company_data))\n",
    "            counter += 1\n",
    "\n",
    "    return pd.DataFrame(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 468/468 [03:08<00:00,  2.49it/s]\n"
     ]
    }
   ],
   "source": [
    "company_scores = processByLength(esg_corpus, keywordBank, len(esg_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataframe: 468\n",
      "Print the first 5 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Companies</th>\n",
       "      <th>Opportunities in Clean Tech Sentiment Score</th>\n",
       "      <th>Carbon Emissions Sentiment Score</th>\n",
       "      <th>Water Stress Sentiment Score</th>\n",
       "      <th>Electronic Waste Sentiment Score</th>\n",
       "      <th>Toxic Emissions &amp; Waste Sentiment Score</th>\n",
       "      <th>Human Capital Development Sentiment Score</th>\n",
       "      <th>Privacy and Data Security Sentiment Score</th>\n",
       "      <th>Labor Management Sentiment Score</th>\n",
       "      <th>Governance Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enea</td>\n",
       "      <td>0.425327</td>\n",
       "      <td>0.557400</td>\n",
       "      <td>0.072240</td>\n",
       "      <td>0.234367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375837</td>\n",
       "      <td>0.355967</td>\n",
       "      <td>0.327428</td>\n",
       "      <td>0.284460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TIS, Inc</td>\n",
       "      <td>0.521842</td>\n",
       "      <td>0.432322</td>\n",
       "      <td>0.996200</td>\n",
       "      <td>0.239570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.535148</td>\n",
       "      <td>0.416305</td>\n",
       "      <td>0.501125</td>\n",
       "      <td>0.564920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sopra Steria Group</td>\n",
       "      <td>0.504519</td>\n",
       "      <td>0.281237</td>\n",
       "      <td>0.347221</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>0.144443</td>\n",
       "      <td>0.452177</td>\n",
       "      <td>0.392583</td>\n",
       "      <td>0.459815</td>\n",
       "      <td>0.456827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rackspace Technology Global, Inc</td>\n",
       "      <td>0.544586</td>\n",
       "      <td>0.101990</td>\n",
       "      <td>0.229163</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.542300</td>\n",
       "      <td>0.213250</td>\n",
       "      <td>0.465908</td>\n",
       "      <td>0.532997</td>\n",
       "      <td>0.347849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Infomedia Ltd</td>\n",
       "      <td>0.341683</td>\n",
       "      <td>-0.401900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483650</td>\n",
       "      <td>0.396403</td>\n",
       "      <td>0.375560</td>\n",
       "      <td>0.378634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Companies  \\\n",
       "0                              Enea   \n",
       "1                          TIS, Inc   \n",
       "2                Sopra Steria Group   \n",
       "3  Rackspace Technology Global, Inc   \n",
       "4                     Infomedia Ltd   \n",
       "\n",
       "   Opportunities in Clean Tech Sentiment Score  \\\n",
       "0                                     0.425327   \n",
       "1                                     0.521842   \n",
       "2                                     0.504519   \n",
       "3                                     0.544586   \n",
       "4                                     0.341683   \n",
       "\n",
       "   Carbon Emissions Sentiment Score  Water Stress Sentiment Score  \\\n",
       "0                          0.557400                      0.072240   \n",
       "1                          0.432322                      0.996200   \n",
       "2                          0.281237                      0.347221   \n",
       "3                          0.101990                      0.229163   \n",
       "4                         -0.401900                      0.000000   \n",
       "\n",
       "   Electronic Waste Sentiment Score  Toxic Emissions & Waste Sentiment Score  \\\n",
       "0                          0.234367                                 0.000000   \n",
       "1                          0.239570                                 0.000000   \n",
       "2                          0.022540                                 0.144443   \n",
       "3                          0.006082                                 0.542300   \n",
       "4                          0.547075                                 0.000000   \n",
       "\n",
       "   Human Capital Development Sentiment Score  \\\n",
       "0                                   0.375837   \n",
       "1                                   0.535148   \n",
       "2                                   0.452177   \n",
       "3                                   0.213250   \n",
       "4                                   0.483650   \n",
       "\n",
       "   Privacy and Data Security Sentiment Score  \\\n",
       "0                                   0.355967   \n",
       "1                                   0.416305   \n",
       "2                                   0.392583   \n",
       "3                                   0.465908   \n",
       "4                                   0.396403   \n",
       "\n",
       "   Labor Management Sentiment Score  Governance Sentiment Score  \n",
       "0                          0.327428                    0.284460  \n",
       "1                          0.501125                    0.564920  \n",
       "2                          0.459815                    0.456827  \n",
       "3                          0.532997                    0.347849  \n",
       "4                          0.375560                    0.378634  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Length of dataframe: {len(company_scores)}\")\n",
    "print(\"Print the first 5 rows\")\n",
    "company_scores.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the market capitalisation and ESG risk ratings data were processed from a differetn file, we will be importing the processed data so as to append to our current feature collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data on ESG risk ratings\n",
    "corporate = pd.read_csv('Corporate2.0.csv')\n",
    "\n",
    "# Filter out those that contains the report\n",
    "corporate_new = corporate.loc[corporate['Annual Report'].notnull()].reset_index(drop=True)\n",
    "\n",
    "# Select relevant columns\n",
    "corporate_new = corporate_new[['Companies', 'ESG Risk Score', 'ESG Risk Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data on market cap\n",
    "mkt_cap = pd.read_csv('mktcap_file5_withoutNA.csv')\n",
    "mkt_cap.rename({'mktcapUSD': 'Market Capitalisation'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have processed our dataframe for company's ESG risk ratings as well as the market cap, we will merge it with our main dataframe on ESG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with ESG risk ratings dataframe\n",
    "corporate_new_merged = pd.merge(corporate_new, company_scores, how='inner', on='Companies').reset_index(drop=True)\n",
    "\n",
    "# Merge with Market Cap dataframe\n",
    "final = pd.merge(corporate_new_merged, mkt_cap, how='inner', on='Companies').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataframe: 403\n",
      "Print the first 5 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Companies</th>\n",
       "      <th>ESG Risk Score</th>\n",
       "      <th>ESG Risk Rating</th>\n",
       "      <th>Opportunities in Clean Tech Sentiment Score</th>\n",
       "      <th>Carbon Emissions Sentiment Score</th>\n",
       "      <th>Water Stress Sentiment Score</th>\n",
       "      <th>Electronic Waste Sentiment Score</th>\n",
       "      <th>Toxic Emissions &amp; Waste Sentiment Score</th>\n",
       "      <th>Human Capital Development Sentiment Score</th>\n",
       "      <th>Privacy and Data Security Sentiment Score</th>\n",
       "      <th>Labor Management Sentiment Score</th>\n",
       "      <th>Governance Sentiment Score</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Market Capitalisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24SevenOffice Group</td>\n",
       "      <td>24.6</td>\n",
       "      <td>Medium ESG Risk</td>\n",
       "      <td>0.357958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471713</td>\n",
       "      <td>0.375589</td>\n",
       "      <td>0.218405</td>\n",
       "      <td>0.330786</td>\n",
       "      <td>719.F</td>\n",
       "      <td>9.212487e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2U, Inc</td>\n",
       "      <td>19.8</td>\n",
       "      <td>Low ESG Risk</td>\n",
       "      <td>0.226180</td>\n",
       "      <td>-0.077200</td>\n",
       "      <td>-0.07720</td>\n",
       "      <td>-0.077200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563257</td>\n",
       "      <td>0.406256</td>\n",
       "      <td>0.275578</td>\n",
       "      <td>0.390339</td>\n",
       "      <td>TWOU</td>\n",
       "      <td>9.673635e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Absolute Software Corp</td>\n",
       "      <td>24.1</td>\n",
       "      <td>Medium ESG Risk</td>\n",
       "      <td>-0.279050</td>\n",
       "      <td>-0.229400</td>\n",
       "      <td>-0.42150</td>\n",
       "      <td>-0.421500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231411</td>\n",
       "      <td>0.827100</td>\n",
       "      <td>0.488943</td>\n",
       "      <td>ABST</td>\n",
       "      <td>4.188821e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>9.7</td>\n",
       "      <td>Negligible ESG Risk</td>\n",
       "      <td>0.632968</td>\n",
       "      <td>0.453108</td>\n",
       "      <td>-0.42150</td>\n",
       "      <td>0.744725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.610265</td>\n",
       "      <td>0.381267</td>\n",
       "      <td>0.518605</td>\n",
       "      <td>0.600880</td>\n",
       "      <td>ACN</td>\n",
       "      <td>2.170000e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACI Worldwide, Inc</td>\n",
       "      <td>20.8</td>\n",
       "      <td>Medium ESG Risk</td>\n",
       "      <td>0.399900</td>\n",
       "      <td>0.353917</td>\n",
       "      <td>0.47024</td>\n",
       "      <td>0.177225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.678200</td>\n",
       "      <td>0.290737</td>\n",
       "      <td>0.232244</td>\n",
       "      <td>0.263880</td>\n",
       "      <td>ACIW</td>\n",
       "      <td>3.068757e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Companies  ESG Risk Score      ESG Risk Rating  \\\n",
       "0     24SevenOffice Group            24.6      Medium ESG Risk   \n",
       "1                 2U, Inc            19.8         Low ESG Risk   \n",
       "2  Absolute Software Corp            24.1      Medium ESG Risk   \n",
       "3               Accenture             9.7  Negligible ESG Risk   \n",
       "4      ACI Worldwide, Inc            20.8      Medium ESG Risk   \n",
       "\n",
       "   Opportunities in Clean Tech Sentiment Score  \\\n",
       "0                                     0.357958   \n",
       "1                                     0.226180   \n",
       "2                                    -0.279050   \n",
       "3                                     0.632968   \n",
       "4                                     0.399900   \n",
       "\n",
       "   Carbon Emissions Sentiment Score  Water Stress Sentiment Score  \\\n",
       "0                          0.000000                       0.00000   \n",
       "1                         -0.077200                      -0.07720   \n",
       "2                         -0.229400                      -0.42150   \n",
       "3                          0.453108                      -0.42150   \n",
       "4                          0.353917                       0.47024   \n",
       "\n",
       "   Electronic Waste Sentiment Score  Toxic Emissions & Waste Sentiment Score  \\\n",
       "0                          0.000000                                      0.0   \n",
       "1                         -0.077200                                      0.0   \n",
       "2                         -0.421500                                      0.0   \n",
       "3                          0.744725                                      0.0   \n",
       "4                          0.177225                                      0.0   \n",
       "\n",
       "   Human Capital Development Sentiment Score  \\\n",
       "0                                   0.471713   \n",
       "1                                   0.563257   \n",
       "2                                   0.000000   \n",
       "3                                   0.610265   \n",
       "4                                   0.678200   \n",
       "\n",
       "   Privacy and Data Security Sentiment Score  \\\n",
       "0                                   0.375589   \n",
       "1                                   0.406256   \n",
       "2                                   0.231411   \n",
       "3                                   0.381267   \n",
       "4                                   0.290737   \n",
       "\n",
       "   Labor Management Sentiment Score  Governance Sentiment Score Ticker  \\\n",
       "0                          0.218405                    0.330786  719.F   \n",
       "1                          0.275578                    0.390339   TWOU   \n",
       "2                          0.827100                    0.488943   ABST   \n",
       "3                          0.518605                    0.600880    ACN   \n",
       "4                          0.232244                    0.263880   ACIW   \n",
       "\n",
       "   Market Capitalisation  \n",
       "0           9.212487e+07  \n",
       "1           9.673635e+08  \n",
       "2           4.188821e+08  \n",
       "3           2.170000e+11  \n",
       "4           3.068757e+09  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Length of dataframe: {len(final)}\")\n",
    "print(\"Print the first 5 rows\")\n",
    "final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company not found: NASDAQ_HCAT_2019\n",
      "1 discrepancy/discrepancies found!\n"
     ]
    }
   ],
   "source": [
    "# Check which columns do not match\n",
    "coy_sorted = company_scores.sort_values(['Companies'])\n",
    "coy_sorted = coy_sorted[['Companies']].reset_index(drop=True)\n",
    "\n",
    "corporate_new_sorted = corporate_new.sort_values(['Companies'])\n",
    "corporate_new_sorted = corporate_new_sorted[['Companies']].reset_index(drop=True)\n",
    "\n",
    "count = 0\n",
    "for company in list(coy_sorted['Companies']):\n",
    "    if company not in list(corporate_new_sorted['Companies']):\n",
    "        print(f\"Company not found: {company}\")\n",
    "        count += 1\n",
    "print(f\"{count} discrepancy/discrepancies found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for the number of pages per report\n",
    "def page_count(file_path):\n",
    "    with fitz.open(file_path) as doc:\n",
    "        return len(doc)\n",
    "\n",
    "# ESG Corpus\n",
    "path = 'Reports 2.0'\n",
    "esg_reports = glob.glob(path + '/*.pdf')\n",
    "report_pages = {}\n",
    "for report in esg_reports:\n",
    "    report_pages[reportName(report)] = page_count(report)\n",
    "\n",
    "# Create a new column for the number of sentences per report\n",
    "company_sentences = {}\n",
    "for company, sentences in esg_corpus.items():\n",
    "    company_sentences[company] = len(sentences)\n",
    "    \n",
    "\n",
    "# Create a new column that tracks the number of words in each report\n",
    "words = {}\n",
    "for company, sentences in esg_corpus.items():\n",
    "    sentences_combined = ' '.join(sentences)\n",
    "    words[company] = len(sentences_combined.split(' '))\n",
    "    \n",
    "final['Page Count'] = final['Companies'].apply(lambda x: report_pages[x])\n",
    "final['Sentence Count'] = final['Companies'].apply(lambda x: company_sentences[x])\n",
    "final['Word Count'] = final['Companies'].apply(lambda x: words[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataframe: 403\n",
      "Print the first 5 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Companies</th>\n",
       "      <th>ESG Risk Score</th>\n",
       "      <th>ESG Risk Rating</th>\n",
       "      <th>Opportunities in Clean Tech Sentiment Score</th>\n",
       "      <th>Carbon Emissions Sentiment Score</th>\n",
       "      <th>Water Stress Sentiment Score</th>\n",
       "      <th>Electronic Waste Sentiment Score</th>\n",
       "      <th>Toxic Emissions &amp; Waste Sentiment Score</th>\n",
       "      <th>Human Capital Development Sentiment Score</th>\n",
       "      <th>Privacy and Data Security Sentiment Score</th>\n",
       "      <th>Labor Management Sentiment Score</th>\n",
       "      <th>Governance Sentiment Score</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Market Capitalisation</th>\n",
       "      <th>Page Count</th>\n",
       "      <th>Sentence Count</th>\n",
       "      <th>Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24SevenOffice Group</td>\n",
       "      <td>24.6</td>\n",
       "      <td>Medium ESG Risk</td>\n",
       "      <td>0.357958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471713</td>\n",
       "      <td>0.375589</td>\n",
       "      <td>0.218405</td>\n",
       "      <td>0.330786</td>\n",
       "      <td>719.F</td>\n",
       "      <td>9.212487e+07</td>\n",
       "      <td>44</td>\n",
       "      <td>251</td>\n",
       "      <td>8575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2U, Inc</td>\n",
       "      <td>19.8</td>\n",
       "      <td>Low ESG Risk</td>\n",
       "      <td>0.226180</td>\n",
       "      <td>-0.077200</td>\n",
       "      <td>-0.07720</td>\n",
       "      <td>-0.077200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563257</td>\n",
       "      <td>0.406256</td>\n",
       "      <td>0.275578</td>\n",
       "      <td>0.390339</td>\n",
       "      <td>TWOU</td>\n",
       "      <td>9.673635e+08</td>\n",
       "      <td>38</td>\n",
       "      <td>156</td>\n",
       "      <td>5429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Absolute Software Corp</td>\n",
       "      <td>24.1</td>\n",
       "      <td>Medium ESG Risk</td>\n",
       "      <td>-0.279050</td>\n",
       "      <td>-0.229400</td>\n",
       "      <td>-0.42150</td>\n",
       "      <td>-0.421500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231411</td>\n",
       "      <td>0.827100</td>\n",
       "      <td>0.488943</td>\n",
       "      <td>ABST</td>\n",
       "      <td>4.188821e+08</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>9.7</td>\n",
       "      <td>Negligible ESG Risk</td>\n",
       "      <td>0.632968</td>\n",
       "      <td>0.453108</td>\n",
       "      <td>-0.42150</td>\n",
       "      <td>0.744725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.610265</td>\n",
       "      <td>0.381267</td>\n",
       "      <td>0.518605</td>\n",
       "      <td>0.600880</td>\n",
       "      <td>ACN</td>\n",
       "      <td>2.170000e+11</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>4690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACI Worldwide, Inc</td>\n",
       "      <td>20.8</td>\n",
       "      <td>Medium ESG Risk</td>\n",
       "      <td>0.399900</td>\n",
       "      <td>0.353917</td>\n",
       "      <td>0.47024</td>\n",
       "      <td>0.177225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.678200</td>\n",
       "      <td>0.290737</td>\n",
       "      <td>0.232244</td>\n",
       "      <td>0.263880</td>\n",
       "      <td>ACIW</td>\n",
       "      <td>3.068757e+09</td>\n",
       "      <td>39</td>\n",
       "      <td>150</td>\n",
       "      <td>4914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Companies  ESG Risk Score      ESG Risk Rating  \\\n",
       "0     24SevenOffice Group            24.6      Medium ESG Risk   \n",
       "1                 2U, Inc            19.8         Low ESG Risk   \n",
       "2  Absolute Software Corp            24.1      Medium ESG Risk   \n",
       "3               Accenture             9.7  Negligible ESG Risk   \n",
       "4      ACI Worldwide, Inc            20.8      Medium ESG Risk   \n",
       "\n",
       "   Opportunities in Clean Tech Sentiment Score  \\\n",
       "0                                     0.357958   \n",
       "1                                     0.226180   \n",
       "2                                    -0.279050   \n",
       "3                                     0.632968   \n",
       "4                                     0.399900   \n",
       "\n",
       "   Carbon Emissions Sentiment Score  Water Stress Sentiment Score  \\\n",
       "0                          0.000000                       0.00000   \n",
       "1                         -0.077200                      -0.07720   \n",
       "2                         -0.229400                      -0.42150   \n",
       "3                          0.453108                      -0.42150   \n",
       "4                          0.353917                       0.47024   \n",
       "\n",
       "   Electronic Waste Sentiment Score  Toxic Emissions & Waste Sentiment Score  \\\n",
       "0                          0.000000                                      0.0   \n",
       "1                         -0.077200                                      0.0   \n",
       "2                         -0.421500                                      0.0   \n",
       "3                          0.744725                                      0.0   \n",
       "4                          0.177225                                      0.0   \n",
       "\n",
       "   Human Capital Development Sentiment Score  \\\n",
       "0                                   0.471713   \n",
       "1                                   0.563257   \n",
       "2                                   0.000000   \n",
       "3                                   0.610265   \n",
       "4                                   0.678200   \n",
       "\n",
       "   Privacy and Data Security Sentiment Score  \\\n",
       "0                                   0.375589   \n",
       "1                                   0.406256   \n",
       "2                                   0.231411   \n",
       "3                                   0.381267   \n",
       "4                                   0.290737   \n",
       "\n",
       "   Labor Management Sentiment Score  Governance Sentiment Score Ticker  \\\n",
       "0                          0.218405                    0.330786  719.F   \n",
       "1                          0.275578                    0.390339   TWOU   \n",
       "2                          0.827100                    0.488943   ABST   \n",
       "3                          0.518605                    0.600880    ACN   \n",
       "4                          0.232244                    0.263880   ACIW   \n",
       "\n",
       "   Market Capitalisation  Page Count  Sentence Count  Word Count  \n",
       "0           9.212487e+07          44             251        8575  \n",
       "1           9.673635e+08          38             156        5429  \n",
       "2           4.188821e+08           2              19         474  \n",
       "3           2.170000e+11          15             150        4690  \n",
       "4           3.068757e+09          39             150        4914  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Length of dataframe: {len(final)}\")\n",
    "print(\"Print the first 5 rows\")\n",
    "final.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation of data\n",
    "Before exporting the data for model training, testing and validation, we will normalise all columns of our features. Since sentiment scores range between -1 and 1, we will not be normalising them for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['Market Capitalisation'] = final['Market Capitalisation'] / final['Market Capitalisation'].max()\n",
    "final['Page Count'] = final['Page Count'] / final['Page Count'].max()\n",
    "final['Sentence Count'] = final['Sentence Count'] / final['Sentence Count'].max()\n",
    "final['Word Count'] = final['Word Count'] / final['Word Count'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output data to csv file\n",
    "final.to_csv('data.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9752b7c63c718e983fa11481b2e75c93f6621b5e127a78d084fb09b3855c71e2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
